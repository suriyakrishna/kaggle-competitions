{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "\n",
    "[here](https://www.kaggle.com/competitions/digit-recognizer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import layers, optimizerss, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/input/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'label'\n",
    "pixels = train_df.columns.drop(label).tolist()\n",
    "\n",
    "X = train_df[pixels].to_numpy()\n",
    "y = train_df[label]\n",
    "\n",
    "# Reshape each row to 28 * 26 (Image)\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalizing/Rescaling Pixel Values\n",
    "X = X / 255\n",
    "\n",
    "# Determine number of distinct label types\n",
    "n_labels = y.unique().shape[0]\n",
    "\n",
    "# Onehot Encoding Labels\n",
    "y = tf.one_hot(y, n_labels).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_unseen = test_df[pixels].to_numpy()\n",
    "X_test_unseen = X_test_unseen.reshape(-1, 28, 28, 1)\n",
    "X_test_unseen = X_test_unseen / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               51328     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,562\n",
      "Trainable params: 57,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 25s 21ms/step - loss: 0.3114 - categorical_accuracy: 0.9147 - val_loss: 0.1257 - val_categorical_accuracy: 0.9638\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 23s 22ms/step - loss: 0.0896 - categorical_accuracy: 0.9756 - val_loss: 0.0816 - val_categorical_accuracy: 0.9760\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 21s 20ms/step - loss: 0.0598 - categorical_accuracy: 0.9833 - val_loss: 0.0666 - val_categorical_accuracy: 0.9807\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 24s 23ms/step - loss: 0.0433 - categorical_accuracy: 0.9878 - val_loss: 0.0593 - val_categorical_accuracy: 0.9811\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 74s 70ms/step - loss: 0.0323 - categorical_accuracy: 0.9913 - val_loss: 0.0543 - val_categorical_accuracy: 0.9832\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 26s 25ms/step - loss: 0.0270 - categorical_accuracy: 0.9924 - val_loss: 0.0482 - val_categorical_accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 26s 25ms/step - loss: 0.0190 - categorical_accuracy: 0.9950 - val_loss: 0.0531 - val_categorical_accuracy: 0.9821\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 30s 28ms/step - loss: 0.0163 - categorical_accuracy: 0.9960 - val_loss: 0.0484 - val_categorical_accuracy: 0.9832\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 29s 28ms/step - loss: 0.0148 - categorical_accuracy: 0.9957 - val_loss: 0.0478 - val_categorical_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 25s 24ms/step - loss: 0.0104 - categorical_accuracy: 0.9977 - val_loss: 0.0527 - val_categorical_accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2069956d5e0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "        layers.Conv2D(filters=32, kernel_size=3),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(filters=16, kernel_size=3),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Compiling our model with appropriate loss function and optimizer\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer= 'adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "#Fitting the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 7s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Predict on test unseen\n",
    "y_unseen_predicted = model.predict(X_test_unseen)\n",
    "\n",
    "# Transform labels\n",
    "y_unseen_predicted = tf.argmax(y_unseen_predicted, axis = 1).numpy()\n",
    "\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "output = pd.read_csv(\"./data/input/sample_submission.csv\", index_col=0)\n",
    "output['Label'] = y_unseen_predicted\n",
    "\n",
    "# output.to_csv(f\"./data/output/digit_recognizer_{now}.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
