{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "yRIUT6ilMN7J"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import layers, optimizers, losses, metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_path = \"./data/transformed/\"\n",
        "\n",
        "if any([\"COLAB\" in x for x in list(os.environ.keys())]):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    data_path = r\"/content/drive/MyDrive/Colab Notebooks/digit-recognizer/data/input/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBzdXkbFNAHf",
        "outputId": "323e36c4-af3a-4b3c-e1bc-729c5ee54fa4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R {data_path.replace(\" \", \"\\\\ \")}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_dr19pBNG-4",
        "outputId": "b2b2dc12-e923-46bf-ebad-b22ab61f6671"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Colab Notebooks/digit-recognizer/data/input/':\n",
            "digit-recognizer.zip  sample_submission.csv  test.csv  train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class DigitTensor:\n",
        "    X: tf.Tensor\n",
        "    y: tf.Tensor\n",
        "\n",
        "\n",
        "class Transform:\n",
        "    def __init__(self, data_path, classes):\n",
        "        self._data_path = data_path\n",
        "        self.classes = classes\n",
        "        self.train_df = pd.read_csv(data_path + \"train.csv\")\n",
        "        self.test_df = pd.read_csv(data_path + \"test.csv\")\n",
        "\n",
        "    def transform(self, train = True):\n",
        "        if train:\n",
        "            X, y = self.train_df.iloc[:, 1:].to_numpy(), self.train_df.iloc[:, 0].to_numpy()\n",
        "\n",
        "            # onehot encode labels\n",
        "            y = self.transform_y(y)\n",
        "        else:\n",
        "            X, y = self.test_df.iloc[:, 0:].to_numpy(), None\n",
        "\n",
        "        return self.transform_X(X), y\n",
        "\n",
        "    def transform_X(self, X):\n",
        "        # Reshape Row Pixels to Image (height x width)\n",
        "        X = X.reshape(-1, 28, 28)\n",
        "\n",
        "        # Rescale Image by padding (32, 32)\n",
        "        X = np.pad(X, 2, mode = 'edge')[2:-2]\n",
        "\n",
        "        # Reshape to include channel (height x width x channels)\n",
        "        X = X.reshape(-1, 32, 32, 1)\n",
        "\n",
        "        # Include RGB channel (height x width x 3)\n",
        "        X = np.repeat(X, 3, axis = -1)\n",
        "\n",
        "        # Normalize\n",
        "        X = X / 255.\n",
        "\n",
        "        return tf.constant(X)\n",
        "\n",
        "    def transform_y(self, y):\n",
        "        return tf.one_hot(y, depth = self.classes)\n",
        "\n",
        "    def train_test_split(self, X, y, train_ratio = 0.8):\n",
        "        num = X.shape[0]\n",
        "\n",
        "        # generate indicies\n",
        "        indicies = np.arange(num, dtype = np.int32)\n",
        "\n",
        "        #  shuffle\n",
        "        np.random.shuffle(indicies)\n",
        "\n",
        "        # get indicies\n",
        "        stop_index = int(train_ratio * num)\n",
        "        train_indicies, test_indicies = indicies[:stop_index].tolist(), indicies[stop_index:].tolist()\n",
        "\n",
        "        X_train, y_train = tf.gather(X, train_indicies), tf.gather(y, train_indicies)\n",
        "        X_test, y_test = tf.gather(X, test_indicies), tf.gather(y, test_indicies)\n",
        "\n",
        "        return DigitTensor(X_train, y_train), DigitTensor(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "Q-aRHJYFNPL3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digit_input_tranformer = Transform(data_path = data_path, classes = 10)\n",
        "\n",
        "X, y = digit_input_tranformer.transform()\n",
        "X_test_unseen, y_test_unseen = digit_input_tranformer.transform(train = False)\n",
        "\n",
        "train_tensor, test_tensor = digit_input_tranformer.train_test_split(X, y)"
      ],
      "metadata": {
        "id": "wUSLODHzNVK9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50"
      ],
      "metadata": {
        "id": "B7c3CIb0i07E"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = ResNet50(include_top = False, input_shape = train_tensor.X.shape[1:], pooling = 'avg')\n",
        "\n",
        "resnet.trainable = True\n",
        "\n",
        "# resnet.summary()\n",
        "\n",
        "classifier = keras.Sequential(\n",
        "    [\n",
        "        resnet,\n",
        "        layers.Dense(128, activation = 'sigmoid'),\n",
        "        layers.Dense(10, activation = 'softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "classifier.compile(\n",
        "    optimizer = optimizers.Adam(learning_rate = 1e-3, decay = 1e-3),\n",
        "    loss = losses.CategoricalCrossentropy(),\n",
        "    metrics = [metrics.CategoricalAccuracy()]\n",
        ")\n",
        "\n",
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK3V3bKQjZQV",
        "outputId": "85229e1f-52ce-4576-ec56-32cf3b8cb104"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,851,274\n",
            "Trainable params: 23,798,154\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier.fit(\n",
        "    train_tensor.X,\n",
        "    train_tensor.y,\n",
        "    epochs = 30,\n",
        "    batch_size = 32,\n",
        "    validation_data = (test_tensor.X, test_tensor.y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXxT59GOjxzg",
        "outputId": "08d0bbbf-0a3e-46ad-a8cf-051fb189af6b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1050/1050 [==============================] - 49s 40ms/step - loss: 0.2238 - categorical_accuracy: 0.9433 - val_loss: 0.1113 - val_categorical_accuracy: 0.9699\n",
            "Epoch 2/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0710 - categorical_accuracy: 0.9823 - val_loss: 0.0489 - val_categorical_accuracy: 0.9874\n",
            "Epoch 3/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 0.0461 - categorical_accuracy: 0.9888 - val_loss: 0.0362 - val_categorical_accuracy: 0.9899\n",
            "Epoch 4/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 0.0302 - categorical_accuracy: 0.9925 - val_loss: 0.0339 - val_categorical_accuracy: 0.9911\n",
            "Epoch 5/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0231 - categorical_accuracy: 0.9942 - val_loss: 0.0346 - val_categorical_accuracy: 0.9905\n",
            "Epoch 6/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0160 - categorical_accuracy: 0.9959 - val_loss: 0.0400 - val_categorical_accuracy: 0.9901\n",
            "Epoch 7/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0173 - categorical_accuracy: 0.9958 - val_loss: 0.0310 - val_categorical_accuracy: 0.9915\n",
            "Epoch 8/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0101 - categorical_accuracy: 0.9975 - val_loss: 0.0336 - val_categorical_accuracy: 0.9923\n",
            "Epoch 9/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0066 - categorical_accuracy: 0.9985 - val_loss: 0.0285 - val_categorical_accuracy: 0.9930\n",
            "Epoch 10/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0069 - categorical_accuracy: 0.9981 - val_loss: 0.0346 - val_categorical_accuracy: 0.9918\n",
            "Epoch 11/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 0.0058 - categorical_accuracy: 0.9984 - val_loss: 0.0308 - val_categorical_accuracy: 0.9926\n",
            "Epoch 12/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0054 - categorical_accuracy: 0.9988 - val_loss: 0.0324 - val_categorical_accuracy: 0.9931\n",
            "Epoch 13/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0060 - categorical_accuracy: 0.9987 - val_loss: 0.0378 - val_categorical_accuracy: 0.9911\n",
            "Epoch 14/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0029 - categorical_accuracy: 0.9995 - val_loss: 0.0390 - val_categorical_accuracy: 0.9925\n",
            "Epoch 15/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 0.0028 - categorical_accuracy: 0.9994 - val_loss: 0.0351 - val_categorical_accuracy: 0.9927\n",
            "Epoch 16/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 0.0026 - categorical_accuracy: 0.9994 - val_loss: 0.0404 - val_categorical_accuracy: 0.9926\n",
            "Epoch 17/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - val_loss: 0.0380 - val_categorical_accuracy: 0.9930\n",
            "Epoch 18/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0032 - categorical_accuracy: 0.9992 - val_loss: 0.0389 - val_categorical_accuracy: 0.9933\n",
            "Epoch 19/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0023 - categorical_accuracy: 0.9996 - val_loss: 0.0396 - val_categorical_accuracy: 0.9926\n",
            "Epoch 20/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 0.0443 - val_categorical_accuracy: 0.9925\n",
            "Epoch 21/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0022 - categorical_accuracy: 0.9995 - val_loss: 0.0431 - val_categorical_accuracy: 0.9924\n",
            "Epoch 22/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 0.0013 - categorical_accuracy: 0.9998 - val_loss: 0.0394 - val_categorical_accuracy: 0.9926\n",
            "Epoch 23/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0016 - categorical_accuracy: 0.9998 - val_loss: 0.0435 - val_categorical_accuracy: 0.9925\n",
            "Epoch 24/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 6.1137e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0418 - val_categorical_accuracy: 0.9936\n",
            "Epoch 25/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 7.2742e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0446 - val_categorical_accuracy: 0.9931\n",
            "Epoch 26/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 0.0016 - categorical_accuracy: 0.9997 - val_loss: 0.0431 - val_categorical_accuracy: 0.9931\n",
            "Epoch 27/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 0.0395 - val_categorical_accuracy: 0.9937\n",
            "Epoch 28/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 8.0146e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0392 - val_categorical_accuracy: 0.9933\n",
            "Epoch 29/30\n",
            "1050/1050 [==============================] - 42s 40ms/step - loss: 6.8528e-04 - categorical_accuracy: 0.9999 - val_loss: 0.0392 - val_categorical_accuracy: 0.9936\n",
            "Epoch 30/30\n",
            "1050/1050 [==============================] - 40s 38ms/step - loss: 4.3912e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0434 - val_categorical_accuracy: 0.9935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Predict on test unseen\n",
        "y_unseen_predicted = classifier.predict(X_test_unseen)\n",
        "\n",
        "# Transform labels\n",
        "y_unseen_predicted = tf.argmax(y_unseen_predicted, axis = 1).numpy()\n",
        "\n",
        "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "output = pd.read_csv(data_path + \"sample_submission.csv\", index_col=0)\n",
        "output['Label'] = y_unseen_predicted\n",
        "\n",
        "output.to_csv(f\"{data_path}/../output/digit_recognizer_{now}.csv\", index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AXsIYXPvHCN",
        "outputId": "59faa45c-de88-4aaa-caf0-b914ef1f0941"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875/875 [==============================] - 9s 10ms/step\n"
          ]
        }
      ]
    }
  ]
}